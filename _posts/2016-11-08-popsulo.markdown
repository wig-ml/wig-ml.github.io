---
layout: post
mathjax: true
title:  "Czy coś się zepsuło?"
date:   2016-11-08
categories: jekyll update
---

Sugerując się prawem nagłówków Bertridge'a - rzecz jasna, nie. Nic się nie zepsuło, bo nieprzetworzone dane prawdopodobnie od początku do niczego się nie nadawały. Przede wszystkim ciężko dopatrzeć się tutaj jakiejkolwiek separowalności - choć to nie jeszcze samo w sobie nic nie znaczy.

<div class="imgcap">
<img src="/assets/neural-net/densityplot.png">
</div>


Bez żadnej informacji wykresy nie wyglądają na niosące szczególnie wartościową informację. Co one zatem przedstawiają? Każdy z powyższych wykresów mianowicie reprezentuje jedną z dziesięciu zmiennych pozycyjnych naszych wektorów wejściowych ze zbioru treningowego ( po znormalizowaniu tak, aby mieć samą zmienność ceny, bez jej bezwzględnego poziomu ) - dla $S=1, L=10, R=1$, czyli kolejno dziesięć dni przed dniem obecny, dziewięć, osiem, i tak dalej... Czerwona krzywa to gęstość prawdopodobieństwa, że wektor posiadający wartość z danej przedziału ( bo wykres gęstości prawdopodobieństwa powstał z histogramu o 50 'koszykach' ) będzie w klasie spadkowej, niebieska - dodatniej. Sytuacji nie poprawia zignorowanie normalizacji - choć mogłoby się tak wydawać, bo ich średnie poziomy dla tych dwóch wyróżnionych klas są różne - co z tego, skoro mamy gigantyczne odchylenia standardowe, przez co w praktyce zbiory te zachodzą na siebie. ( średnie to $~110, 140$, a odchylenia standardowe osiągają ponad $600$. )

Powyższe nie musi być jednakże przesłanką rozstrzygającą na temat beznadziejności zbioru treningowego - gdybym narysował podobne krzywe dla przytaczanego już zbioru spiralnego, okazałoby się, że są one analogicznie nie do odróżnienia, a jednak sieć się uczy i z powodzeniem klasyfikuje przynależność. Były one jednakże jednoznacznie separowalne. Tutaj, najwidoczniej, separowalności brak, a powyższe, jeśli nie rozstrzyga, to pomaga się do tej tezy przychylić. Można pobawić się parametrami, zmienić skok, długość, wreszcie zasięg, ale nie za wiele to zmienia. Potrzebujemy więcej informacji, informacji innego typu niż zwyczajne ruchy cen. Wolumen, równie łatwy do pozyskania jak ruchy cen, jest podobnie jak one bez niczego więcej bezużyteczny. Albo sieć sama zrobi z niej użytek, albo sami jej podpowiemy, jak ma to zrobić.

Co jest najlepszą informacją, jaką mamy? Moglibyśmy spróbować włączyć informację o raportach kwartalnych - ale znacznie nam to ogranicza liczbę danych treningowych. Poza tym, podejrzewam, że z komunikatów, które spółki giełdowe czasem publikują, takich jak te o dodatkowych opcjach menedżerskich czy zmianie struktury akcjonariatu, można coś wyciągnąć. Niemniej wyciąganie danych z tekstu będzie niezwykle uciążliwe - ale do zrobienia. Zajmę się tym później.

Nie włączyliśmy jeszcze do równania punktu odniesienia, jakim jest indeks giełdowy. Inwestorzy często podejmują decyzję odnośnie zakupu spółki bazując na tym, jak perspektywy wzrostu mają się do całego rynku - stąd popularne określenie "pokonać rynek". Poza prymitywnym sprawdzeniem, jak spółka rośnie/spada w porównaniu do rynku, istnieje jeszcze metryka bardziej skomplikowana - tak zwane Sharpe Ratio. Mówi ona nam, jak inwestycja w dany papier prezentuje się, gdy weźmiemy jeszcze pod uwagę, jak ryzykowna jest to inwestycja. Innymi słowy, pewien zwrot z ryzykownego waloru nie będzie tak korzystny jak taki sam zwrot z papieru bardziej spokojnego i zrównoważonego. 

Widać drobną poprawę - przede wszystkim funkcja kosztu na zbiorze testowym schodzi poniżej 0.7 nieco chętniej niż poprzednio, jednocześnie mam wrażenie, że mogło się pojawić drobne przeuczenie. Niemniej nie jest ono na tyle duże, by warto było na niej skupiać wysiłki, chwilowo trzeba zająć się podwyższeniem dokładności.

<div class="imgcap">
<img src="/assets/neural-net/withwig.png">
</div>

Użyte do wygenerowania wykresu parametry:
<div>
$S = 5, L = 10$;
$S = 2, L = 19$;
$S = 5, L = 13$;
$S = 3, L = 12$;
$S = 1, L = 5$;
$S = 5, L = 15$
</div>

Czas na ręczne wkładanie metryk.

<div class="imgcap">
<img src="/assets/neural-net/sharpe.png">
</div>

No, powkładałem. Mam wrażenie, że wystąpiła drobna poprawa - ale tak czy siak w dalszym ciągu posuwamy się bardzo drobymi krokami - trzeba będzie czegoś więcej. Cofnę się o kilka kroków i spróbuję sprawdzić, co może stanowić zmienną separującą, ale najpierw ucieknę do modeli "state-of-art" w dziedzinie przewidywania szeregów czasowych - rekurencyjnych sieci neuronowych.



W akcie desperacji spróbuję wyciągnąć dane z komunikatów giełdowych na temat raportów - ale myślę, że może mi to trochę zająć. Na czym bowiem polega przeszkoda? Potrzebne mi są informacje na temat tego, kiedy dana spółka opublikowała raport  - nie możemy włączyć do wektorów informacji na temat raportów, który nie został jeszcze opublikowany! Zdobycie samych raportów było w zasadzie bezproblemowe, poza małymi problemami z Selenium (narzędzie do parsowania stron), ponieważ przechowywane były w formie znormalizowanej, tabelkowej. Informacje na temat daty publikacji każda firma publikuje po swojemu - jedna opublikuje w formacie liczbowym "dzien.miesiac.rok", inna "20 stycznia 2015", jeszcze inna opublikuje w innym terminie raporty skonsolidowane i jednostkowe. Gdyby tego było, częstym zjawiskiem jest zmiana daty publikacji, wtedy pojawia się specjalny komunikat "zmiana terminu publikacji raportów" - ale tytuł oczywiście też jest zależny od podmiotu, który publikuje taką informację.

W następnym odcinku - analiza eksploracyjna ruchów cen i wiadomości.


